package org.homermultitext.utils

import java.text.Normalizer
import java.text.Normalizer.Form

import edu.holycross.shot.safecsv.SafeCsvReader

import edu.harvard.chs.cite.CtsUrn
import edu.harvard.chs.cite.CiteUrn
import edu.harvard.chs.cite.Orca

class ParseableStringOrca {



  /** Ordered list of ORCA objects with parseable strings. */
  ArrayList tokenList = []
  
  /** URN, as a String value, for the collection generated by this analysis.*/
  String orcaName

  
  LinkedHashMap byzMappings = [:]  

  LinkedHashMap byzToModern = [:]

  /** HMT Lexical validation object. */
  LexicalValidation lexer

  /** String used to separate columns in tab files.*/
  String tabSeparator = "#"

  



  /** Contstruction with all required data.
   * @param collectionName Collection-level URN for this analysis, as a string value.
   * @param byzAuthList Two-column .csv file with authority list for Byzantine
   * orthographic variants.
   * @param altOrthList Two-column .csv file with authority list for modern
   * orthographic variants.
   * @param morphComd Path to executable morphological parser.
   */
  ParseableStringOrca(String collectionName, File byzAuthList, File altOrthList, String morphCmd) {
    orcaName = collectionName
    lexer = new LexicalValidation(byzAuthList, altOrthList, morphCmd)
    byzToModern = indexByzForms(byzAuthList)
  }


  /** Maps accepted Byzantine forms to standard orthography
   * used as the "transformed text" value for this ORCA analysis.
   * @param authList .csv file with HMT Byzantine orthographic equivalents.
   * Byzantine form is in second column, modern form is in third.
   */
  LinkedHashMap indexByzForms(File authList) {
    LinkedHashMap validForms = [:]
    SafeCsvReader srcReader = new SafeCsvReader(authList)
    srcReader.readAll().each { lexLine ->
      String trimmed = lexLine[1].replaceAll(/^[ ]+/,"")
      trimmed = trimmed.replaceAll(/[ ]+$/,"")
      String normalizedByz = Normalizer.normalize(trimmed, Form.NFC)
      
      String trimmedModern = lexLine[2].replaceAll(/^[ ]+/,"")
      trimmedModern = trimmedModern.replaceAll(/[ ]+$/,"")
      String normalizedModern = Normalizer.normalize(trimmedModern, Form.NFC)
      validForms[normalizedByz] = normalizedModern
    }
    return validForms
  }


  
  /** Creates an ordered list of Orca objects from a HMT tabular file.
   * @param tabFile File with tabular representation of text to analyze.
   * @returns An ordered list of Orca objects.
   */
  ArrayList orcafyTabFile(File tabFile)
  throws Exception {
    return orcafyTabFile(tabFile,0)
  }


  /** Creates an ordered list of Orca objects from a HMT tabular file.
   * @param tabFile File with tabular representation of text to analyze.
   * @param index Index value to use in generating IDs for Orca objects.
   * @returns An ordered list of Orca objects.
   */
  ArrayList orcafyTabFile(File tabFile, Integer index)
  throws Exception {

    ArrayList orcaList = []
    
    HmtEditorialTokenization tokenizer  = new HmtEditorialTokenization()
    tokenizer.tokenizeTabFile(tabFile, tabSeparator).each { tokenization ->
      index++;
      CiteUrn orcaId = new CiteUrn(orcaName + "." + index)
      Orca orca = null

      CtsUrn passageUrn
      CiteUrn analysis
      try {
	passageUrn = new CtsUrn(tokenization[0])
	analysis = new CiteUrn(tokenization[1])
      } catch (Exception e) {
	throw e
      }
      

      switch (analysis.getCollection()) {
	
      case "tokentypes":
      if (analysis.getObjectId() == "lexical") {

	String intermediateAnalysis =  lexer.validateToken(passageUrn)
	switch (intermediateAnalysis) {
	case "success":
	orca = new Orca(orcaId, passageUrn, analysis, passageUrn.getSubref())
	break
	
	case "byz":
	String normalForm = Normalizer.normalize(passageUrn.getSubref(), Form.NFC)
	orca = new Orca(orcaId, passageUrn, analysis, byzToModern[normalForm] )
	// add entry to byz tracking map
	break

	case "alt":
	orca = new Orca(orcaId, passageUrn, analysis, "ALT MAPPING FROM " + passageUrn.getSubref())
	break
	

	case "fail":
	orca = new Orca(orcaId, passageUrn, analysis, "FAIL-" + passageUrn.getSubref())
	break
	}
      }      
      break

      case "pers":
      case "place":
      case "peoples":
      orca = new Orca(orcaId, passageUrn, analysis, passageUrn.getSubref())
      break

      default :
      System.err.println "===>Unrecognized: ${analysis.getCollection()}"
      break
      }
      if (orca != null) {
	orcaList.add(orca)
      }
    }
    return orcaList
  }




  
  LinkedHashMap mapByzForms(File tabFile) {
  }
  
}
